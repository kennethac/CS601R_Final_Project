{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarsBaseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw0jxft9bHjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pandas as pd\n",
        "import importlib\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7S0e9Nba-I",
        "colab_type": "code",
        "outputId": "cc6ca3b5-2423-4fa6-9c89-e46ac4833949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGJs-Ioxh8OK",
        "colab_type": "code",
        "outputId": "fd5a8d4c-5e7a-4f94-f31e-aa4d8c5ba733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# !curl -OL https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
        "!cp /content/gdrive/My\\ Drive/SimCLR/data/stanfordCars/car_devkit.tgz .\n",
        "# !curl -OL http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "!cp /content/gdrive/My\\ Drive/SimCLR/data/stanfordCars/cars_train.tgz .\n",
        "# !curl -OL http://imagenet.stanford.edu/internal/car196/cars_test.tgz\n",
        "!cp /content/gdrive/My\\ Drive/SimCLR/data/stanfordCars/cars_test.tgz .\n",
        "!tar xvf car_devkit.tgz\n",
        "!tar xf cars_train.tgz\n",
        "!tar xf cars_test.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "devkit/\n",
            "devkit/cars_meta.mat\n",
            "devkit/cars_train_annos.mat\n",
            "devkit/cars_test_annos.mat\n",
            "devkit/README.txt\n",
            "devkit/train_perfect_preds.txt\n",
            "devkit/eval_train.m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AralNp7fchwR",
        "colab_type": "code",
        "outputId": "28a9eb4b-ca0f-45b6-ebc3-0d94bf4bc8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!rm -rf CS601R_Final_Project/ models/ datasets/ notebooks/\n",
        "!git clone https://github.com/webMan1/CS601R_Final_Project.git\n",
        "!cp -r CS601R_Final_Project/* ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS601R_Final_Project'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 99 (delta 49), reused 72 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzduA1ICfqNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datasets.StanfordCarsDataset\n",
        "import models.CLRDecoder\n",
        "import importlib\n",
        "\n",
        "datasets.StanfordCarsDataset = importlib.reload(datasets.StanfordCarsDataset)\n",
        "models.CLRDecoder = importlib.reload(models.CLRDecoder)\n",
        "\n",
        "CLRDecoder = models.CLRDecoder.CLRDecoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prbpxCGQe5cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CarsEndToEndBaseline(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CarsEndToEndBaseline, self).__init__()\n",
        "    resnet = torchvision.models.resnet50(pretrained=False)\n",
        "    self.encoder = nn.Sequential(*list(resnet.children())[:-1])\n",
        "    self.clr = CLRDecoder(196, True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x).view((-1, 2048))\n",
        "    decoded = self.clr(encoded)\n",
        "    return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYoN8Gu0f-cc",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hivzWiPLf7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, train_loader, valid_loader, num_epochs:int, valid_freq:int=10):\n",
        "  train_len = len(train_loader)\n",
        "  valid_len = len(valid_loader)\n",
        "  loop = tqdm(total=(num_epochs * train_len + (num_epochs // valid_freq) * valid_len), position=0)\n",
        "\n",
        "  train_losses = []\n",
        "  train_accs = []\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "\n",
        "  criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    loss_builder = []\n",
        "    acc_builder = []\n",
        "\n",
        "    for i, (x, y_truth) in enumerate(train_loader):\n",
        "      x, y_truth = x.cuda(async=False), y_truth.long().squeeze(1).cuda(async=False)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      y_hat = model(x)\n",
        "\n",
        "      total_loss = criteria(y_hat, y_truth)\n",
        "      total_loss.backward()\n",
        "\n",
        "      acc = y_truth.eq(y_hat.argmax(1)).sum().item() / len(y_truth)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_builder.append(total_loss.item())\n",
        "      acc_builder.append(acc)\n",
        "\n",
        "      loop.update(1)\n",
        "      loop.set_description(f\"Epoch: {e}, it: {i}/{train_len}. Loss: {total_loss.item()}. Acc: {acc}\")\n",
        "    \n",
        "    train_accs.append(acc_builder)\n",
        "    train_losses.append(loss_builder)\n",
        "\n",
        "    if e % valid_freq == 0:\n",
        "      loss_builder = []\n",
        "      acc_builder = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for i, (x, y_truth) in enumerate(valid_loader):\n",
        "          x, y_truth = x.cuda(async=False), y_truth.long().squeeze(1).cuda(async=False)\n",
        "\n",
        "        y_hat = model(x)\n",
        "\n",
        "        total_loss = criteria(y_hat, y_truth)\n",
        "        acc = y_truth.eq(y_hat.argmax(1)).sum().item() / len(y_truth)\n",
        "\n",
        "        loss_builder.append(total_loss.item())\n",
        "        acc_builder.append(acc)\n",
        "\n",
        "        loop.update(1)\n",
        "        loop.set_description(f\"[VALIDATING] Epoch: {e}, it: {i}/{valid_len}. Loss: {total_loss.item()}. Acc: {acc}\")\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      valid_accs.append(acc_builder)\n",
        "      valid_losses.append(loss_builder)\n",
        "    \n",
        "    state = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"train_losses\": train_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"valid_losses\": valid_losses,\n",
        "        \"valid_accs\": valid_accs,\n",
        "        \"epoch\": e\n",
        "    }\n",
        "    num = ((e + 4) // 5) * 5\n",
        "    path = f\"/content/gdrive/My Drive/SimCLR/models/stanford/e2e_e_{num}_linear.mod\"\n",
        "    torch.save(state, path)\n",
        "\n",
        "  return train_losses, train_accs, valid_losses, valid_accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGTmijoxgAX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_training():\n",
        "  batch_size = 32\n",
        "  model = CarsEndToEndBaseline().cuda()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  train_loader = datasets.StanfordCarsDataset.get_loader(True, batch_size)\n",
        "  valid_loader = datasets.StanfordCarsDataset.get_loader(False, batch_size)\n",
        "\n",
        "  num_epochs = 10\n",
        "  \n",
        "  train_losses, train_accs, valid_losses, valid_accs = train(model, optimizer, train_loader, valid_loader, num_epochs=num_epochs, valid_freq=5)\n",
        "\n",
        "  return train_losses, train_accs, valid_losses, valid_accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNNpRxyVnOrd",
        "colab_type": "code",
        "outputId": "e4b7dd91-a2a2-42f1-dc4c-926083a13850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_losses, train_accs, valid_losses, valid_accs = run_training()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, it: 254/255. Loss: 5.283675193786621. Acc: 0.0:   8%|▊         | 255/3054 [03:29<36:37,  1.27it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6dikuZmngMt",
        "colab_type": "code",
        "outputId": "e3ef46e2-23e8-447c-e277-0519a11ca88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls content/car_ims"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'content/car_ims': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}